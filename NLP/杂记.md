### softmax

#### 简述

softmax用于多分类过程中，将多个神经元的输出映射到【0,1】空间上，对于单个元素的softmax值就是：
$$
S_i=\frac{e^i}{\sum_je^j}
$$
对于softmax的函数作用后，所有值累积和是1（也就是相当于概率和为1）；同时对于每一个输出相当于后验概率，选取概率最大的节点就是我们的预测目标。

#### 设计初衷

对于softmax主要是希望特征对概率的影响是乘性的，同时对于互斥的多分类使用softmax会优于多个logistic的二分类。





### LSTM

首先看一下RNN（我们关注的一直是h的变化）：

![RNN-unrolled](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\RNN-unrolled.png)

经过删减之后的模块结构：

![LSTM3-SimpleRNN](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\LSTM3-SimpleRNN.png)

因此我们加入了LSTM后：

![LSTM3-chain](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\LSTM3-chain.png)



我们分别观察每一部分：



![step1](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\step1.webp)

第二部分：

![step2](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\step2.webp)

第三部分：

![step3](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\step3.webp)

第四部分：

![step4](F:\github\Blockchain PaperReading\Blockchain-PaperReading\NLP\step4.webp)

